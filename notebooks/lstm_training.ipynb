{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "lstm-training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Torch3.6",
      "language": "python",
      "name": "torch3.6"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xelav/Insider-Threat-CERT/blob/master/notebooks/lstm_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6xD3mBh1o3"
      },
      "source": [
        "# Preparing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AgRFqtOWg-Y",
        "outputId": "dafef255-a09b-48a2-95be-07d23efd81cd"
      },
      "source": [
        "from pathlib import Path\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "drive_dir = Path('/content/drive/My Drive/')\n",
        "root_dir = Path('/content')\n",
        "\n",
        "assert drive_dir.is_dir()\n",
        "assert root_dir.is_dir()\n",
        "\n",
        "%cd \"{root_dir}\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHY3STlL2GhT"
      },
      "source": [
        "repo_dir = drive_dir / 'CERT'\n",
        "assert repo_dir.is_dir()\n",
        "\n",
        "import sys\n",
        "sys.path.append(str(repo_dir))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34c07MuxWief"
      },
      "source": [
        "# repo_dir = \"/content/repo\"\n",
        "# !git clone https://github.com/xelav/Insider-Threat-CERT \"$repo_dir\"\n",
        "\n",
        "# import sys\n",
        "# sys.path.append(repo_dir)\n",
        "\n",
        "# repo_branch = 'master'\n",
        "# %cd \"{repo_dir}\"\n",
        "# !git checkout $repo_branch\n",
        "# !git fetch\n",
        "# !git reset origin/$repo_branch --hard\n",
        "# %cd \"{root_dir}\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zS2z6WysWwLj",
        "outputId": "8ade0937-c154-4e23-874d-1e1b9063797e"
      },
      "source": [
        "!pip install pytorch-ignite\n",
        "!pip install ipdb\n",
        "%pip install wandb==0.8.18 -q\n",
        "\n",
        "import wandb\n",
        "wandb.login()\n",
        "wandb.__version__"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-ignite\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/d3/640f70d69393b415e6a29b27c735047ad86267921ad62682d1d756556d48/pytorch_ignite-0.4.4-py3-none-any.whl (200kB)\n",
            "\r\u001b[K     |█▋                              | 10kB 25.5MB/s eta 0:00:01\r\u001b[K     |███▎                            | 20kB 31.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 20.8MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 40kB 24.3MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 51kB 22.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 61kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 71kB 17.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 81kB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 92kB 17.3MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 102kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 112kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 122kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 133kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 143kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 153kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 163kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 174kB 16.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 184kB 16.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 194kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 204kB 16.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.8.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.7.4.3)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.4\n",
            "Collecting ipdb\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/3d/9a7fa78cf59b95ac46663cfb760e63854dd66a267cda573c1a2f95f87c19/ipdb-0.13.7.tar.gz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from ipdb) (54.1.2)\n",
            "Collecting ipython>=7.17.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/43/6dbd0610550708fc418ad027fda97b5f415da9053749641654fdacfec93f/ipython-7.21.0-py3-none-any.whl (784kB)\n",
            "\u001b[K     |████████████████████████████████| 788kB 39.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from ipdb) (0.10.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (0.7.5)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (0.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (5.0.5)\n",
            "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/eb/e6/4b4ca4fa94462d4560ba2f4e62e62108ab07be2e16a92e594e43b12d3300/prompt_toolkit-3.0.18-py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 49.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (4.4.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.17.0->ipdb) (0.8.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3; sys_platform != \"win32\"->ipython>=7.17.0->ipdb) (0.7.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython>=7.17.0->ipdb) (0.2.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.17.0->ipdb) (0.2.5)\n",
            "Building wheels for collected packages: ipdb\n",
            "  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipdb: filename=ipdb-0.13.7-cp37-none-any.whl size=11434 sha256=746b18f66cf176c5df9ac4ff536445eea92721198947a4dbe32b5ea5b9fc4933\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/e2/66/bde554f8029ad1c5288f3bf427a78b18ec670182d7e670efe6\n",
            "Successfully built ipdb\n",
            "\u001b[31mERROR: jupyter-console 5.2.0 has requirement prompt-toolkit<2.0.0,>=1.0.0, but you'll have prompt-toolkit 3.0.18 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 7.21.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: prompt-toolkit, ipython, ipdb\n",
            "  Found existing installation: prompt-toolkit 1.0.18\n",
            "    Uninstalling prompt-toolkit-1.0.18:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.18\n",
            "  Found existing installation: ipython 5.5.0\n",
            "    Uninstalling ipython-5.5.0:\n",
            "      Successfully uninstalled ipython-5.5.0\n",
            "Successfully installed ipdb-0.13.7 ipython-7.21.0 prompt-toolkit-3.0.18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "IPython",
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.3MB 22.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 58.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 13.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 11.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 163kB 35.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 256kB 55.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 10.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 184kB 41.6MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://app.wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Not authenticated.  Copy a key from https://app.wandb.ai/authorize\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "API Key: ··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.8.18'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4UElZ3n6yT3"
      },
      "source": [
        "# branch_name = 'master'\n",
        "\n",
        "# %cd \"{repo_dir}\"\n",
        "# !git reset --hard\n",
        "# !git checkout new-cnn-parameters\n",
        "# !git fetch\n",
        "# !git reset origin/new-cnn-parameters --hard\n",
        "# %cd \"{root_dir}\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgpmeEcuWevq"
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "\n",
        "import torch.utils.data\n",
        "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator, Engine\n",
        "from ignite.metrics import Accuracy, Loss\n",
        "\n",
        "from src.models import InsiderClassifier, LSTM_Encoder, LSTM_Encoder_Topics, LSTM_Encoder_Numeric\n",
        "from src.params import get_params\n",
        "from src.dataset import CertDataset, create_data_loaders\n",
        "from src.lstm_trainer import *"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVO1YA9EWevy"
      },
      "source": [
        "# Prepare run config\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEtu_Bb52j7P",
        "outputId": "984a0903-3d5c-44bc-ad91-f9f9745c673f"
      },
      "source": [
        "%ls \"{drive_dir}\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " asdf                           \u001b[0m\u001b[01;34mnotebooks\u001b[0m/\n",
            "'Book Rewards.gsheet'           NY_feasting_supplies.gdoc\n",
            " \u001b[01;34mBooks\u001b[0m/                         private_key.ppk\n",
            " \u001b[01;34mCERT\u001b[0m/                          \u001b[01;34mruns\u001b[0m/\n",
            "\u001b[01;34m'Colab Notebooks'\u001b[0m/              \u001b[01;36mscan2020_10_29_14_58_52.bmp_2\u001b[0m@\n",
            " \u001b[01;34mCoursera\u001b[0m/                     'Untitled Diagram.drawio'\n",
            " \u001b[01;34mDatasets\u001b[0m/                      \u001b[01;34mwandb\u001b[0m/\n",
            " df_final.pkl                  \u001b[01;34m'Work Docs'\u001b[0m/\n",
            " \u001b[01;34mDocs\u001b[0m/                         'Новый документ.gdoc'\n",
            " edu-cmc-skmodel20-620-01.pub  'План работ.gdoc'\n",
            " expert.drawio                 'Результаты моделей-2020.gdoc'\n",
            " intermediate.drawio           'Результаты моделей.gdoc'\n",
            " \u001b[01;34mmasked_lm\u001b[0m/                    \u001b[01;34m'Телеком - документация'\u001b[0m/\n",
            " \u001b[01;34mmasked_lm_enc\u001b[0m/                 Финансы.gsheet\n",
            " \u001b[01;34mMSU\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvDuY40Oz2Ha"
      },
      "source": [
        "dataset_version = '6.2'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-RYORHyWevz"
      },
      "source": [
        "output_dir = Path(f'{drive_dir}/Datasets/CERT_output_v{dataset_version}')\n",
        "answers_dir = Path(f\"{drive_dir}/Datasets/CERT/answers\")\n",
        "main_answers_file = answers_dir / \"insiders.csv\"\n",
        "\n",
        "assert(output_dir.is_dir())\n",
        "assert(answers_dir.is_dir())\n",
        "\n",
        "# log_dir = output_dir / 'logs' / run_name\n",
        "# checkpoint_dir = output_dir / 'checkpoints' / run_name\n",
        "\n",
        "# run_name = 'lstm/content-test7'\n",
        "\n",
        "# assert(not log_dir.is_dir())\n",
        "# assert(not checkpoint_dir.is_dir())\n",
        "\n",
        "# if log_dir.is_dir():\n",
        "#     shutil.rmtree(log_dir)\n",
        "# if checkpoint_dir.is_dir():\n",
        "#     shutil.rmtree(checkpoint_dir)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H46Bp7wIloqJ"
      },
      "source": [
        "# monkeypatch symlinks. For some reason, colab doesn't allow to make symlinks on some files\n",
        "# No idea why this happens, so i did this. It's bad, but it's works.\n",
        "import os\n",
        "from shutil import copyfile\n",
        "os.symlink = copyfile"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6-qkE9LWev4"
      },
      "source": [
        "params = get_params()\n",
        "params['model']['lstm_encoder']['embedding_size'] = None\n",
        "params['model']['lstm_encoder']['use_content_topics'] = False\n",
        "params['model']['lstm_encoder']['condition_vec_size'] = None\n",
        "\n",
        "# This is a mess of the code..\n",
        "\n",
        "# add content topics\n",
        "# WARNING: don't mix embeddings with content topics!\n",
        "# params['model']['lstm_encoder']['input_size']"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ei2Yjxsr7e58"
      },
      "source": [
        "# actions, targets = CertDataset.prepare_dataset(output_dir / 'aggregated.pkl',\n",
        "#                                                main_answers_file,\n",
        "#                                                min_length=50,\n",
        "#                                                max_length=200,\n",
        "#                                                )"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOq3noG49Xiy",
        "outputId": "0cac64c1-553b-4819-b5c1-e5b021e104e6"
      },
      "source": [
        "df = pd.read_parquet(output_dir / 'final_df.parquet')\n",
        "\n",
        "enable_conditional_vecs = False\n",
        "if enable_conditional_vecs:\n",
        "    conditional_vecs = df.drop(['action_id', 'malicious', 'user', 'period'], axis=1).values\n",
        "    params['model']['lstm_encoder']['condition_vec_size'] = conditional_vecs.shape[1]\n",
        "else:\n",
        "    conditional_vecs = None\n",
        "\n",
        "print(\"Padding_actions\")\n",
        "df.action_id = CertDataset.pad_to_length_numpy(df.action_id, max_length=200)\n",
        "actions = df.action_id.values\n",
        "targets = df['malicious']\n",
        "del df \n",
        "import gc\n",
        "gc.collect()\n",
        "actions = np.vstack(actions)\n",
        "\n",
        "params['model']['lstm_encoder']['use_content_topics'] = False\n",
        "content = None\n",
        "if params['model']['lstm_encoder']['use_content_topics']:\n",
        "    content_values = df.content.values\n",
        "    content_values = CertDataset.pad_topic_matricies(content_values, max_length=200)\n",
        "    content = df.content\n",
        "\n",
        "cert_dataset = CertDataset(actions, targets,\n",
        "                           content_topics=None,\n",
        "                           conditional_vecs=conditional_vecs)\n",
        "train_loader, val_loader = create_data_loaders(cert_dataset, validation_split=0.3, random_seed=0, batch_size=1024)\n",
        "\n",
        "device = 'cuda'\n",
        "\n",
        "# del actions, reduced_labels, ukeys, index, values, arrays\n",
        "# gc.collect()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Padding_actions\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cazH9aaLR6M3"
      },
      "source": [
        "# Prepare trainers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYiSvV1_83hT"
      },
      "source": [
        "del params['model']['cnn_classifier']\n",
        "del params['train']['cnn_classifier']\n",
        "# params['data_granularity'] = GRANULARITY"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "id": "BsAj4EEMWewA",
        "outputId": "abc633d8-c258-4422-a670-8011a9bf2e31"
      },
      "source": [
        "wandb.init(project=f\"cert{dataset_version}-lstm\", config=params)\n",
        "checkpoint_dir = Path(wandb.run.dir) / 'checkpoints'\n",
        "\n",
        "if params['model']['lstm_encoder']['use_content_topics']:\n",
        "    LSTM_model = LSTM_Encoder_Topics\n",
        "elif params['model']['lstm_encoder']['condition_vec_size']:\n",
        "    LSTM_model = LSTM_Encoder_Numeric\n",
        "else:\n",
        "    LSTM_model = LSTM_Encoder\n",
        "lstm_encoder = LSTM_model(params['model']['lstm_encoder'])\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(lstm_encoder.parameters())\n",
        "\n",
        "train_engine = create_supervised_trainer_lstm(\n",
        "                                        lstm_encoder, optimizer, criterion, device=device,\n",
        "                                        prepare_batch=prepare_batch_lstm,\n",
        "                                        checkpoint_dir=checkpoint_dir,\n",
        "                                       )\n",
        "\n",
        "val_engine = create_supervised_evaluator_lstm(\n",
        "        lstm_encoder, device=device,\n",
        "        prepare_batch=prepare_batch_lstm,\n",
        "        metrics={},\n",
        "        criterion=criterion,\n",
        "        checkpoint_dir=checkpoint_dir,\n",
        ")\n",
        "\n",
        "@train_engine.on(Events.STARTED)\n",
        "def log_training_results(trainer):\n",
        "    print('Initial validation run:')\n",
        "    val_engine.train_epoch = 0\n",
        "    val_engine.run(val_loader)\n",
        "\n",
        "    wandb.run.summary[\"best_val_non_pad_accuracy\"] = val_engine.state.metrics['non_pad_accuracy']\n",
        "    wandb.run.summary[\"best_val_loss\"] = val_engine.state.metrics['epoch_loss']\n",
        "\n",
        "@train_engine.on(Events.EPOCH_COMPLETED)\n",
        "def log_training_results(trainer):\n",
        "    val_engine.train_epoch = train_engine.state.epoch\n",
        "    val_engine.run(val_loader)\n",
        "\n",
        "    if val_engine.state.metrics['non_pad_accuracy'] > wandb.run.summary[\"best_val_non_pad_accuracy\"]:\n",
        "        wandb.run.summary[\"val_non_pad_accuracy\"] = val_engine.state.metrics['non_pad_accuracy']\n",
        "        wandb.run.summary[\"best_val_loss\"] = val_engine.state.metrics['epoch_loss']\n",
        "        wandb.run.summary[\"best_train_non_pad_accuracy\"] = train_engine.state.metrics['non_pad_accuracy']\n",
        "        wandb.run.summary[\"best_train_loss\"] = train_engine.state.metrics['epoch_loss']\n",
        "\n",
        "        wandb.save(str(checkpoint_dir) + '/best_model*')\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/xelav/cert6.2-lstm\" target=\"_blank\">https://app.wandb.ai/xelav/cert6.2-lstm</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/xelav/cert6.2-lstm/runs/1il9gj85\" target=\"_blank\">https://app.wandb.ai/xelav/cert6.2-lstm/runs/1il9gj85</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.10.23 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P2jBDiQ6qnM"
      },
      "source": [
        "Load word2vec embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VrBhqjpOGS8"
      },
      "source": [
        "if params['model']['lstm_encoder']['embedding_size']:\n",
        "    pretrained_path = output_dir / 'checkpoints' / 'w2v/test2/final_model_7758.pth'\n",
        "\n",
        "    pretrained_embeddings = torch.load(pretrained_path)\n",
        "    pretrained_embeddings = pretrained_embeddings['embed.weight']\n",
        "\n",
        "    lstm_encoder.embedding = lstm_encoder.embedding.from_pretrained(pretrained_embeddings[:-1])\n",
        "    lstm_encoder.embedding.requires_grad = False"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HK_liPSR9Pf"
      },
      "source": [
        "# Run experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kBSsrds5arl",
        "outputId": "bd1368ea-3427-495c-c361-393e47117f77"
      },
      "source": [
        "params['train']['lstm_encoder']"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 1024, 'lr': 0.001, 'manual_seed': 0, 'num_epochs': 200}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXa6jdBaWewE",
        "outputId": "9849d0bf-9b02-4a66-f6d7-554ae67e38e6"
      },
      "source": [
        "torch.manual_seed(params['train']['lstm_encoder']['manual_seed'])\n",
        "train_engine.run(train_loader,\n",
        "                 max_epochs=params['train']['lstm_encoder']['num_epochs'],\n",
        "                 seed=params['train']['lstm_encoder']['manual_seed']\n",
        "                 )\n",
        "print('finished!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py:656: UserWarning: Argument seed is deprecated. It will be removed in 0.5.0. Please, use torch.manual_seed or ignite.utils.manual_seed\n",
            "  \"Argument seed is deprecated. It will be removed in 0.5.0. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Initial validation run:\n",
            "Validation Results   - Avg loss: 4.110740, Accuracy: 0.003332, Non-Pad-Accuracy: 0.005613\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.10.23 is available!  To upgrade, please run:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 completed!\n",
            "Train Results        - Avg loss: 0.529367, Accuracy: 0.891165, Non-Pad-Accuracy: 0.848086\n",
            "Validation Results   - Avg loss: 0.270159, Accuracy: 0.936748, Non-Pad-Accuracy: 0.885670\n",
            "Epoch 2 completed!\n",
            "Train Results        - Avg loss: 0.242492, Accuracy: 0.941147, Non-Pad-Accuracy: 0.890211\n",
            "Validation Results   - Avg loss: 0.223068, Accuracy: 0.943551, Non-Pad-Accuracy: 0.893895\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9NgR-6ocK0N"
      },
      "source": [
        "best_model_checkpoint = list(checkpoint_dir.glob('best_model_*'))\n",
        "assert(len(best_model_checkpoint) == 1)\n",
        "best_model_checkpoint = best_model_checkpoint[0]\n",
        "\n",
        "files.download(best_model_checkpoint) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecPP92n5ZJsI"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir \"{log_dir}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2O9RKtOETy2p"
      },
      "source": [
        "zip and download logs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "Z-QTj03jSf_Q",
        "outputId": "9be92d55-44d5-43ff-88b2-712194824ee2"
      },
      "source": [
        "log_zip =  output_dir / 'logs' / (run_name + '_logs.zip')\n",
        "!zip -r \"$log_zip\" \"$log_dir\"\n",
        "files.download(log_zip) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/drive/My Drive/Datasets/CERT_output/logs/lstm/random-embeddings/ (stored 0%)\n",
            "  adding: content/drive/My Drive/Datasets/CERT_output/logs/lstm/random-embeddings/train/ (stored 0%)\n",
            "  adding: content/drive/My Drive/Datasets/CERT_output/logs/lstm/random-embeddings/train/events.out.tfevents.1586905646.00b82a3f534b.127.9 (deflated 94%)\n",
            "  adding: content/drive/My Drive/Datasets/CERT_output/logs/lstm/random-embeddings/validation/ (stored 0%)\n",
            "  adding: content/drive/My Drive/Datasets/CERT_output/logs/lstm/random-embeddings/validation/events.out.tfevents.1586905646.00b82a3f534b.127.10 (deflated 73%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy_ynExZWewM"
      },
      "source": [
        "# Prediction exploration\n",
        "\n",
        "TODO:\n",
        "- decode class numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_TCxWxnWewN"
      },
      "source": [
        "batch = next(iter(val_loader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZB0Xl7rWewQ"
      },
      "source": [
        "x, y = prepare_batch_lstm(batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2YuVyQtWewT"
      },
      "source": [
        "lstm_encoder.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28TIt4HrWewX"
      },
      "source": [
        "y.argmax(dim=2)[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDn9CB8XWewb"
      },
      "source": [
        "lstm_encoder(x.to('cuda')).exp().argmax(dim=2)[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRd1ZfCcWewf"
      },
      "source": [
        "lstm_encoder(x.to('cuda')).exp().argmax(dim=2).unique()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}