{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Torch3.6",
      "language": "python",
      "name": "torch3.6"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "w2v-training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AgRFqtOWg-Y",
        "colab_type": "code",
        "outputId": "aec0011d-a16f-4006-e5d5-2d61969b5879",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "root_dir = '/content/drive/My Drive/'\n",
        "\n",
        "%cd \"{root_dir}\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34c07MuxWief",
        "colab_type": "code",
        "outputId": "026dd28e-7195-4ea2-9fab-13e5583b421d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone https://github.com/xelav/Insider-Threat-CERT /root/repo\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"/root/repo\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path '/root/repo' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS2z6WysWwLj",
        "colab_type": "code",
        "outputId": "86f90e0a-a7ff-4e27-ad84-1b6fc5969f13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-ignite in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pytorch-ignite) (1.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4UElZ3n6yT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd \"/root/repo\"\n",
        "!git pull\n",
        "%cd \"{root_dir}\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgpmeEcuWevq",
        "colab_type": "code",
        "outputId": "f5d1d16c-f44d-42e9-8865-b967f2f42857",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import shutil\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch.utils.data\n",
        "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator, Engine\n",
        "from ignite.metrics import Accuracy, Loss\n",
        "\n",
        "from src.models import SkipGram\n",
        "from src.params import get_params\n",
        "from src.dataset import SkipGramDataset, create_data_loaders\n",
        "from src.w2v_trainer import *"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVO1YA9EWevy",
        "colab_type": "text"
      },
      "source": [
        "# TODO:\n",
        "\n",
        "* Больше детерминизма\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-RYORHyWevz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# output_dir = Path(r'C:\\Users\\Mvideo\\Google Drive\\Datasets\\CERT_output')\n",
        "# answers_dir = Path(r\"C:/Users/Mvideo/Downloads/answers\")\n",
        "\n",
        "output_dir = Path(f'{root_dir}/Datasets/CERT_output')\n",
        "answers_dir = Path(f\"{root_dir}/Datasets/CERT/answers\")\n",
        "main_answers_file = answers_dir / \"insiders.csv\"\n",
        "\n",
        "assert(output_dir.is_dir())\n",
        "assert(answers_dir.is_dir())\n",
        "\n",
        "run_name = 'w2v/test2'\n",
        "\n",
        "log_dir = output_dir / 'logs' / run_name\n",
        "checkpoint_dir = output_dir / 'checkpoints' / run_name\n",
        "\n",
        "# assert(not log_dir.is_dir())\n",
        "# assert(not checkpoint_dir.is_dir())\n",
        "\n",
        "if log_dir.is_dir():\n",
        "    shutil.rmtree(log_dir)\n",
        "if checkpoint_dir.is_dir():\n",
        "    shutil.rmtree(checkpoint_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8MfpFzhWev8",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHbK70PEsR8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "actions = SkipGramDataset.prepare_dataset(output_dir / 'aggregated.pkl', min_length=50)\n",
        "dataset = SkipGramDataset(actions, window_size=10)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1024)\n",
        "device = 'cuda'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsAj4EEMWewA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = SkipGram(65, 30)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "train_engine = create_supervised_trainer_skipgram(\n",
        "                                        model, optimizer, device=device,\n",
        "                                        log_dir=log_dir.as_posix(),\n",
        "                                        checkpoint_dir=checkpoint_dir,\n",
        "                                       )\n",
        "\n",
        "train_engine.run(dataloader, max_epochs=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5gmdWvFcXGB",
        "colab_type": "code",
        "outputId": "bb2fe772-4f0a-4d86-c273-5da56aa98ba3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%ls \"{checkpoint_dir}\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "final_model_7758.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9NgR-6ocK0N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download(checkpoint_dir / 'final_model_7758.pth') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecPP92n5ZJsI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir \"{log_dir}\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy_ynExZWewM",
        "colab_type": "text"
      },
      "source": [
        "# Prediction exploration\n",
        "\n",
        "https://projector.tensorflow.org/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFl03-q17AAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import io\n",
        "\n",
        "# encoder = info.features['text'].encoder\n",
        "\n",
        "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for ind in range(65):\n",
        "  vec = model.embed.weight[ind] # skip 0, it's padding.\n",
        "  out_m.write(str(ind) + \"\\n\")\n",
        "  out_v.write('\\t'.join([str(x) for x in vec.cpu().detach().numpy()]) + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0WPfutr7RYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('vecs.tsv')\n",
        "files.download('meta.tsv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}