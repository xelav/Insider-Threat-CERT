{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from src.models import InsiderClassifier, LSTM_Encoder\n",
    "from src.params import get_params\n",
    "from src.dataset import CertDataset, create_data_loaders\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_dir = Path(r'C:\\Users\\Mvideo\\Google Drive\\Datasets\\CERT_output')\n",
    "# answers_dir = Path(r\"C:/Users/Mvideo/Downloads/answers\")\n",
    "\n",
    "output_dir = Path(r'C:\\Users\\admin\\Google Drive\\Datasets\\CERT_output')\n",
    "answers_dir = Path(r\"C:\\Users\\admin\\Google Drive\\Datasets\\CERT\\answers\")\n",
    "main_answers_file = answers_dir / \"insiders.csv\"\n",
    "\n",
    "lstm_checkpoint = output_dir / 'checkpoints/lstm/final2-nll/final_model_3040.pth'\n",
    "assert(lstm_checkpoint.is_file())\n",
    "\n",
    "# run_name = 'cnn/test-weighted-auc'\n",
    "# log_dir = output_dir / 'logs' / run_name\n",
    "# checkpoint_dir = output_dir / 'checkpoints' / run_name\n",
    "\n",
    "# # assert(not log_dir.is_dir())\n",
    "# # assert(not checkpoint_dir.is_dir())\n",
    "\n",
    "# if log_dir.is_dir():\n",
    "#     shutil.rmtree(log_dir)\n",
    "# if checkpoint_dir.is_dir():\n",
    "#     shutil.rmtree(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions, targets = CertDataset.prepare_dataset(output_dir / 'aggregated.pkl', main_answers_file, min_length=50, max_length=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка LSTM-векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "batch = 256\n",
    "\n",
    "cert_dataset = CertDataset(actions, targets)\n",
    "train_loader, val_loader = create_data_loaders(cert_dataset, validation_split=0.3, random_seed=0, batch_size=batch)\n",
    "\n",
    "params = get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_encoder = LSTM_Encoder(params['model']['lstm_encoder'])\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "lstm_encoder.requires_grad = False\n",
    "lstm_encoder.eval()\n",
    "lstm_encoder.load_state_dict(\n",
    "    torch.load(lstm_checkpoint, map_location=torch.device(device)), strict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_batch(batch, device=None, non_blocking=None, num_classes=64, train=True):\n",
    "\n",
    "    actions = batch['actions']\n",
    "\n",
    "    actions = actions.to(device).to(torch.int64)\n",
    "    actions = F.one_hot(actions, num_classes=64).float()\n",
    "    \n",
    "    return actions, batch['targets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_encoded_dataset(loader, model_encoder):\n",
    "    \n",
    "    all_targets = None\n",
    "    vecs = None\n",
    "\n",
    "    for batch in tqdm(loader):\n",
    "        actions, targets = prepare_batch(batch)\n",
    "\n",
    "        result = model_encoder(actions)\n",
    "        result = result.detach().cpu().numpy()\n",
    "        targets = targets.detach().cpu().numpy()\n",
    "\n",
    "        if all_targets is not None:\n",
    "            all_targets = np.concatenate([all_targets, targets], axis=0)\n",
    "        else:\n",
    "            all_targets = targets\n",
    "\n",
    "        if vecs is not None:\n",
    "            vecs = np.concatenate([vecs, result], axis=0)\n",
    "        else:\n",
    "            vecs = result\n",
    "    \n",
    "    return vecs, all_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 130/130 [05:38<00:00,  2.61s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((33276, 200, 40), (33276,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_vecs, val_targets = prepare_encoded_dataset(val_loader, lstm_encoder)\n",
    "val_vecs.shape, val_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 304/304 [20:18<00:00,  4.01s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((77644, 200, 40), (77644,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vecs, train_targets = prepare_encoded_dataset(train_loader, lstm_encoder)\n",
    "train_vecs.shape, train_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((77644, 200, 40), (33276, 200, 40), (77644,), (33276,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vecs.shape, val_vecs.shape, train_targets.shape, val_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(lstm_checkpoint.parent / 'train_vecs.npy', train_vecs)\n",
    "np.save(lstm_checkpoint.parent / 'val_vecs.npy', val_vecs)\n",
    "\n",
    "np.save(lstm_checkpoint.parent / 'train_targets.npy', train_targets)\n",
    "np.save(lstm_checkpoint.parent / 'val_targets.npy', val_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs = np.load(lstm_checkpoint.parent / 'train_vecs.npy')\n",
    "val_vecs = np.load(lstm_checkpoint.parent / 'val_vecs.npy')\n",
    "\n",
    "train_targets = np.load(lstm_checkpoint.parent / 'train_targets.npy')\n",
    "val_targets = np.load(lstm_checkpoint.parent / 'val_targets.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((77644, 200, 40), (33276, 200, 40), (77644,), (33276,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vecs.shape, val_vecs.shape, train_targets.shape, val_targets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестируем классификаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77644, 8000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vecs =train_vecs.reshape(train_vecs.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model.fit(train_vecs, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77644,)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77644, 200, 40)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch3.6",
   "language": "python",
   "name": "torch3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
